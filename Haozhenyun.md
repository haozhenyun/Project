## 智源 - 看山杯 专家发现算法大赛 2019


### 摘要
 数据挖掘是指从大量的数据中通过算法搜索隐藏于其中信息的过程，从海量的互联网数据中通过有效的方法获取到尽可能多的有效的信息，这对于该行业的发展和提升用户的体验都是非常有利的。其中，知识分享服务已经成为目前全球互联网的重要、最受欢迎的应用类型之一。知乎自 2011 年创办至今，已经成为一个拥有 2.2 亿用户，每天有数以十万计的新问题以及 UGC 内容产生的网站。其中，如何高效的将这些用户新提出的问题邀请其他用户进行解答，以及挖掘用户有能力且感兴趣的问题进行邀请下发，优化邀请回答的准确率，提高问题解答率以及回答生产数，成为知乎最重要的课题之一。
本次比赛是智源2019人工智能大赛的任务之一，比赛将提供知乎的问题信息、用户画像、用户回答记录，以及用户接受邀请的记录，要求选手预测这个用户是否会接受某个新问题的邀请。在比赛中，首先对给定的数据集进行了数据预处理操作，然后将数据做了特征工程，提取出有效的特征，有助于提高模型的训练效果，最后使用了LightGBM进行建模训练。
文章将对数据处理过程、特征工程部分以及涉及的模型算法进行介绍，并在文章最后对这次比赛进行了总结和展望。


### 简介
 知乎目前已拥有超过2.2亿的用户，每天产生海量的提问，传统的手动邀请他人回答问题功能已经不能满足用户的需求。故知乎专家推荐系统即问题路由应运而生。问题路由同时也是本次看山杯的题目来源，比赛旨在从选手中征集高效精准的推荐算法，挖掘有能力且感兴趣的用户进行问题地精准推荐。
 
知乎路由工作机制

 问题路由主要包括排序、召回、特征落地三个模块。系统首先根据用户ID向问题路由发起请求，通过用户画像获取用户特征（年龄、兴趣）；然后使用召回模块召回用户潜在能够回答的问题，从数百万的问题中找到几百个问题供排序模块使用；接下来通过特征模块获取问题的相关特征，据此对问题进行精准排序，并将头部问题返回至用户，排序中产生落地的特征会记录在日志中和用于训练模型。
本次比赛所解决的问题主要与这一流程相关，主要是求解问题的ranking阶段，给某个用户推荐一个新问题，判断该用户回答这个问题的概率。
 
知乎问题路由内部实现形式



### 1.	数据分析
#### 1.1	数据集介绍
在本次比赛中，知乎选出一个月的邀请数据作为训练数据，以及后面一周的数据作为评测数据，并对数据进行抽样，正样本保留，负样本采样一部分。比赛提供的数据十分接近实际业务场景，提供的一些embedding数据是经过处理好的，可以直接使用，同时为了保护隐私，对一些相关数据进行了编码处理。如下表所示，表格中列出了比赛提供的几个数据集。

数据集	主要特征	含义
single_word_vectors_64d.txt	单字、embedding	单字向量
word_vectors_64d.txt	词、embedding	词向量
topic_vectors_64d.txt 	话题、embedding	话题向量
question_info_0926.txt	问题ID、问题创建时间…. 问题绑定的话题 ID	包含邀请数据集及回答数据集中涉及到的所有问题列表
answer_info_0926.txt	回答ID、问题ID…. 回答是否被标为优秀回答….	邀请数据集中用户最近2个月内的所有回答
member_info_0926.txt	用户ID、性别…. 用户关注的话题、用户感兴趣的话题	包含邀请数据集中用户相关特征信息
invite_info_0926.txt	邀请的问题ID、被邀请用户ID、邀请创建时间、邀请是否被回答	包含用户最近1个月的邀请数据
 invite_info_evaluate_0926.txt	邀请的问题ID、被邀请用户ID、邀请创建时间	未来7天的问题邀请数据

需依据提供的邀请数据集
[Qxxx   Mxxx  D3-H4   Score]
 
1.邀请的问题ID, 格式为 Qxxx。
2.被邀请用户ID, 格式为 Mxxx。
3.邀请创建时间, 格式为 D3-H4。
4.预测的回答概率值，取值范围 [0, 1]。

#### 1.2	数据预处理
在本次比赛中，知乎给定的数据是已经处理好的。在前期公布的数据基础上，又做了进一步的整理，对一些错误数据和重复数据进行了清洗。所以，对于知乎给定的数据集，我们就可以直接使用了。

### 2.	特征工程
特征对于推荐效果至关重要，本次比赛提供了知乎的核心特征，十分接近实际业务场景，发挥空间较大。在知乎的实际操作中，特征可分为问题侧特征、用户侧特征、交叉特征等，接下来就在这几个方面进行描述。

#### 2.1	问题侧特征
在问题侧特征方面，由于问题本身是一个20个字左右的短文本，可提取的信息有限，所以有必要利用话题、创建时间等相关信息。在文本信息上，可以充分使用所提供的embedding。知乎在实际操作中，也十分看重embedding。由于问题存在话题特征，回答没有，可以将问题的话题特征作为回答的特征。
所以，在这部分的特征工程中，对问题数据集去掉部分特征后，将规范格式后的问题的topic求取了平均值，将平均值与话题数据集中的64维话题embedding进行映射，为了方便后面数据的训练，将这个64维embedding特征转化为64列。
 

#### 2.2	用户侧特征
用户特征包括年龄、性别等基本特征，以及根据用户的历史点击、浏览挖掘的用户兴趣。此外最重要的特征则是用户历史回答特征（时间、长度、字数、赞同数等）。这里需要花费时间做特征工程，以提取到大量特征，如总历史回答数、总赞同数、上次回答时间、回答频率、擅长领域等。
在对用户特征进行处理的时候，还去除了单值特征，因为这些特征对于最后的结果预测没有作用，然后对剩余的多值特征进行了LabelEncoder编码。因为用户特征里也存在着感兴趣话题跟关注话题特征，所以将这两个特征也做了map处理，并转化为64列。
 

#### 2.3	回答侧特征
回答数据集里包含了用户最近2个月内的所有回答，包含问题和用户的ID、回答创建的时间，以及回答是否被推荐、是否包含图片、回答字数、点赞数等特征，将这些特征与问题和用户数据集中的特征进行整合，并从中进一步提取问题和用户的特征信息，可以获取到很大的信息。
将回答创建的时间进行划分，分为训练集和验证集部分，再将回答的某些特征（是否被推荐、回答字数、点赞数等等）计算和、最大值、平均值，并加入到数据集中，这些特征能够有效的提高判断用户是否回答某个问题的准确率。
 

#### 2.4	交叉特征
在单独处理数据集的同时，特征之间的关系也是不容小觑的。用户回答过问题，那用户与问题之间一定就存在着一些关系，比如说用户的计算问题话题和关键词的embedding与用户历史回答话题和关键词的embedding的相似度，这样就可以获得用户历史回答话题与问题话题之间的相关程度，相似度越大，表示用户越有可能回答这种话题的问题。其次，可以参考问题绑定的话题在用户历史回答中反馈情况，如赞同数、反对数等，赞同数越多，那么用户再回答这类问题的可能性就越大。

#### 2.5 时间划分
通过让模型学习提出问题邀请前的用户回答情况，来预测用户在未来7天被邀请后回答问题的概率。通过对数据集的观察，最终训练集选定使用时间窗口为3810-3860的回答数据以及3861-3867的邀请回答数据，测试集选用时间窗口为3817-3867的回答数据以及3845-3867的邀请回答数据。

### 3.	模型选择
模型方面，由于实际业务场景中，对运行时间有较高要求（如500毫秒），很难使用多个模型融合或者复杂模型，所以倾向于单一模型、多目标多任务模型等。GBDT、GBRank之类树模型可解释性强、训练时间短、相对稳定。在比赛中，使用了LightGBM模型，它和XGBoost一样是对GBDT的高效实现，原理上它和GBDT及XGBoost类似，都采用损失函数的负梯度作为当前决策树的残差近似值，去拟合新的决策树。
LightGBM在很多方面会比XGBoost表现的更为优秀。它有以下优势：
•	更快的训练效率
•	低内存使用
•	更高的准确率
•	支持并行化学习
•	可处理大规模数据
•	支持直接使用category特征
LightGBM使用的是histogram算法，占用的内存更低，数据分隔的复杂度更低，在计算上的代价也大幅降低。
 
在Histogram算法之上，LightGBM进行进一步的优化。首先它抛弃了大多数GBDT工具使用的按层生长 (level-wise)的决策树生长策略，而使用了带有深度限制的按叶子生长 (leaf-wise)算法。
 


### 4.	训练与预测
使用LightGBM模型来进行训练
采用5折交叉验证，将数据随机分成5份，每次取1份做为验证集，其余四份作为训练集。
 

### 5.	总结
这次比赛对于我们学习数据挖掘知识有着很大的意义，能够将我们在课堂上学习的理论知识应用到实践中，而且看山杯比赛是对于知乎用户做的一个预测，知乎是我们日常使用的一个软件，非常贴近我们的生活，让我们很快的就了解了这项比赛。比赛中有一些队伍分享了他们的baseline，通过学习他们的baseline，让我学到了很多数据处理和分析的知识，同时也学习到了他们对于数据挖掘方面的热情和努力的精神。通过这次比赛，在将平时学习到的知识应用到实践中的同时，我也认识到了自己在知识实践上面的不足，在今后的学习中，要更加注重学习实践，注重将学习到的知识真正的转化为自己能够熟练应用的知识。


